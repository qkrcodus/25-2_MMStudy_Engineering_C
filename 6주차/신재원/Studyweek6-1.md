네트워크 시스템 에서 **처리율 제한 장치(rate limit)**는 클라이언트 또는 서비스 가 보내는 트래픽의 처리율(rate)을 특정 임계치까지만 제어하기 위한 장치다. 

HTTP를 예로 들면 이 장치는 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한한다. API 요청 횟수가 제한 장치에 정의된 임계치(threshold)를 넘어서면 추가로 도달한 모든 호출은 처리가 중단(block)된다. 규모가 큰 서비스에서는 필수적이다.

> • 사용자는 초당 2회 이 상 새 글을 올릴 수 없다.
• 같은 IP 주소로는 하루에 10개 이상의 계정을 생성할 수 없다.
• 같은 디바이스로는 주당 5회 이상 리워드(reward)를 요청할 수 없다.
# Rate Limit 아키텍쳐 설계
![](https://velog.velcdn.com/images/jaewon77/post/757092c6-a077-4030-b97e-900961b3093c/image.png)


# API에 처리율 제한 장치를 두면 좋은 점

이번 장에서는 바로 이 처리율 제한 장치를 설계한다. 설계에 앞서, API에 처리
율 제한 장치를 두면 좋은 점을 살펴보자.

• DoS(Denial of Service) 공격 에 의 한 자원 고갈(resource starvation)을 방지
할 수 있다. 대형 IT 기업들이 공개한 거의 대부분의 API는 어 떤 형태로든
처 리율 제한 장치를 갖고 있다. 예를 들어 트위터는 3시간 동안 300개의 트
윗만 올릴 수 있도록 제한하고 있다. 구글 독스(Google docs) API는 사용
자당 분당 300회의 read 요청만 허용한다. 처리율 제한 장치는 추가 요청
에 대해서는 처리를 중단함으로써 DoS 공격을 방지한다.

• 비용을 절감한다. 추가 요청에 대한 처리를 제한하면 서버를 많이 두지 않
아도 되고, 우선순위가 높은 API에 더 많은 자원을 할당할 수 있다. 아울러
처리율 제한은 제3자(third-paity) API에 사용료를 지불하고 있는 회사들에
게는 아주 중요하다. 예를 들어, 신용을 확인하거나, 신용카드 결제를 하거
나, 건강 상태를 확인하거나 하기 위해 호출하는 API에 대한 과금이 횟수에
따라 이루어진다면, 그 횟수를 제한할 수 있어야 비용을 절감할 수 있을 것
이다.

• 서버 과부하를 막는다. 봇(bot)에서 오는 트래픽이나 사용자의 잘못된 이용
패턴으로 유발된 트래픽을 걸러내는데 처리율 제한 장치를 활용할 수 있다.

# 요구사항
아래에 시스템 요구사항을 요약하였다.
• 설정된 처리율을 초과하는 요청은 정확하게 제한한다.
• 낮은 응답시간: 이 처리율 제한 장치는 HTTP 응답시간에 나쁜 영향을 주어
서는 곤란하다.
• 가능한 한 적은 메모리를 써야 한다.
• 분산형 처리율 제한(distributed rate limiting)： 하나의 처리율 제한 장치를
여러 서버나 프로세스에서 공유할 수 있어야 한다.
• 예외 처리: 요청이 제한되었을 때는 그 사실을 사용자에게 분명하게 보여주
어야 한다.
• 높은 결함 감내성(fault tolerance)： 제한 장치에 장애가 생기더라도 전체 시
스템 에 영향을 주어서는 안 된다.

# 처리율 제한 알고리즘 

• 토큰 버킷 (token bucket)
• 누출 버킷(leaky bucket)
• 고정 윈도 카운터 (fixed window counter)
• 이동 윈도 로그(sliding window log)
• 이동 윈도 카운터 (sliding window counter)

요청 처리 제한(rate limiting)에서 '버킷(bucket)'과 '윈도(window)'는 시스템이 일정 시간 동안 처리할 수 있는 요청 수를 제어하는 데 사용되는 핵심 개념입니다. 이 두 개념은 함께 작동하여 API 서버나 기타 리소스가 과부하되지 않도록 보호합니다.

버킷(Bucket)
버킷은 요청을 담는 가상의 용기라고 생각하면 이해하기 쉽습니다. 요청 처리 제한 시스템에서 버킷은 일정량의 **토큰(token)**을 가지고 있으며, 각 요청이 들어올 때마다 토큰 하나를 사용합니다. 버킷에 토큰이 남아 있다면 요청은 처리되지만, 토큰이 없다면 요청은 거부되거나 대기 상태가 됩니다.

가장 흔한 버킷 알고리즘은 토큰 버킷(Token Bucket) 알고리즘입니다.

작동 방식: 버킷에는 일정한 속도로 토큰이 채워지며, 버킷이 가득 차면 더 이상 토큰이 추가되지 않습니다. 예를 들어, 1분에 60개의 요청을 처리하도록 설정되어 있다면, 1초에 1개의 토큰이 버킷에 추가됩니다.

장점: 순간적으로 많은 요청이 들어와도 버킷에 토큰이 충분하다면 이를 허용하여 트래픽 버스트(burst)를 효과적으로 처리할 수 있습니다. 예를 들어, 평소에는 요청이 없다가 한 번에 10개의 요청이 들어와도 버킷에 10개 이상의 토큰이 있다면 모두 처리됩니다.

윈도(Window)
윈도는 특정 시간 간격을 의미합니다. 요청 처리 제한 시스템은 이 윈도 내에서 들어오는 요청의 수를 계산하여 제한을 적용합니다. 윈도 개념을 사용하는 가장 일반적인 알고리즘은 고정 윈도(Fixed Window) 알고리즘과 슬라이딩 윈도(Sliding Window) 알고리즘입니다.

## 토큰 버킷 알고리즘 

동작원리
토큰 버킷은 지정된 용량 (정적 용량)을 가지는 컨테이너
토큰 공급기는 사전 설정된 양의 토큰을 주기적으로 추가하고 버킷에 채워진다.
토큰이 꽉 찬 버킷에는 더 이상의 토큰이 추가되지 않고 버려진다. (overflow)
각 요청은 처리될 때 마다 하나의 토큰을 사용하여 요청이 도착하면 버킷에 충분한 토큰이 있는지 검사한다.
충분한 토큰이 있는 경우, 버킷에서 토큰 하나를 꺼낸 후 요청을 시스템에 전달한다.
충분한 토큰이 없는 경우, 해당 요청은 버려진다.


장점
구현이 쉽다.
메모리 사용 측면에서도 효율적이다.
짧은 시간에 집중되는 트래픽도 처리가 가능하다. 버킷에 남은 토큰이 존재만하면 요청은 시스템에 전달된다.

단점
버킷 크기와 토큰 공급률이라는 두 개 인자를 가지고 있는데, 이 값을 적절하게 튜닝하기 어렵다.
버킷 크기 : 처리할 요청의 최대 수
토큰 공급률 : 토큰이 추가되는 속도

경쟁 상태(Race Condition)

경쟁 조건 문제를 해결하는 가장 널리 알려진 해결책은 락이다.

동기화는 분산 환경에서 고려해야할 또 다른 중요한 요소. 

웹 계층은 무상태이므로 동기화를 하지 않으면 처리율 제한을 올바르게 수행할수 없을것이다.







